#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹æƒé‡ä¸‹è½½è„šæœ¬

æ­¤è„šæœ¬ç”¨äºä¸‹è½½æ–‡æ¡£å¢å¼ºæ¨¡å‹çš„é¢„è®­ç»ƒæƒé‡ã€‚
ç”±äºçœŸå®çš„ DocEnTR æ¨¡å‹æƒé‡å¯èƒ½éœ€è¦ä»ç‰¹å®šæ¥æºè·å–ï¼Œ
è¿™é‡Œæä¾›äº†ä¸€ä¸ªé€šç”¨çš„ä¸‹è½½æ¡†æ¶ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ä¸‹è½½é“¾æ¥ã€‚

ä½¿ç”¨æ–¹æ³•:
    python download_model.py
"""

import os
import sys
import requests
from tqdm import tqdm
import hashlib


# æ¨¡å‹é…ç½®
# æ¥æº: https://github.com/dali92002/DocEnTR
MODEL_CONFIGS = {
    'docentr_hdibco2012_base': {
        'name': 'DocEnTR-Base (H-DIBCO 2012) - Patch 8x8',
        'url': 'https://drive.google.com/uc?id=1ZOjnqxeg2620x4qLeqHCCmF3wozPnSDv',
        'filename': 'docentr_hdibco2012_base_8x8.pth',
        'md5': None,
        'psnr': 22.29,
    },
    'docentr_hdibco2012_large': {
        'name': 'DocEnTR-Large (H-DIBCO 2012) - Patch 16x16',
        'url': 'https://drive.google.com/uc?id=1h1bdMg7fvoQv4N5dY9T03c92_ViCMlSM',
        'filename': 'docentr_hdibco2012_large_16x16.pth',
        'md5': None,
        'psnr': 22.04,
    },
    'docentr_dibco2017_base': {
        'name': 'DocEnTR-Base (DIBCO 2017) - Patch 8x8',
        'url': 'https://drive.google.com/uc?id=1zz0aFPNFctjNTVRpng4Lh-1X-Ms6Zroa',
        'filename': 'docentr_dibco2017_base_8x8.pth',
        'md5': None,
        'psnr': 19.11,
    },
    'docentr_dibco2017_large': {
        'name': 'DocEnTR-Large (DIBCO 2017) - Patch 16x16',
        'url': 'https://drive.google.com/uc?id=1Qz8um2nwAMla2AgRnaKEc2JNQnb1w2nH',
        'filename': 'docentr_dibco2017_large_16x16.pth',
        'md5': None,
        'psnr': 18.85,
    },
    'docentr_hdibco2018_base': {
        'name': 'DocEnTR-Base (H-DIBCO 2018) - Patch 8x8',
        'url': 'https://drive.google.com/uc?id=1CpvS9ahZolRz2sJ4PHobofOXVJBMWwD0',
        'filename': 'docentr_hdibco2018_base_8x8.pth',
        'md5': None,
        'psnr': 19.46,
    },
    'docentr_hdibco2018_large': {
        'name': 'DocEnTR-Large (H-DIBCO 2018) - Patch 16x16',
        'url': 'https://drive.google.com/uc?id=1uIzdGMGshX-sxCdWU7CwRE7CJ4b4z5o-',
        'filename': 'docentr_hdibco2018_large_16x16.pth',
        'md5': None,
        'psnr': 19.47,
    },
}

# æ¨¡å‹å­˜å‚¨ç›®å½•
MODELS_DIR = os.path.join(os.path.dirname(__file__), 'models')


def calculate_md5(file_path, chunk_size=8192):
    """è®¡ç®—æ–‡ä»¶çš„ MD5 å€¼"""
    md5_hash = hashlib.md5()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(chunk_size), b''):
            md5_hash.update(chunk)
    return md5_hash.hexdigest()


def download_file_from_google_drive(file_id, dest_path):
    """
    ä» Google Drive ä¸‹è½½æ–‡ä»¶

    Args:
        file_id: Google Drive æ–‡ä»¶ ID
        dest_path: ç›®æ ‡ä¿å­˜è·¯å¾„

    Returns:
        bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
    """
    try:
        print(f"æ­£åœ¨ä» Google Drive ä¸‹è½½ (ID: {file_id})...")

        # åˆ›å»ºç›®æ ‡ç›®å½•
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)

        # ä½¿ç”¨ gdown åº“ä¸‹è½½ï¼ˆæ›´å¯é ï¼‰
        try:
            import gdown
            url = f"https://drive.google.com/uc?id={file_id}"
            gdown.download(url, dest_path, quiet=False)
            return True
        except ImportError:
            print("æç¤º: å®‰è£… gdown å¯ä»¥æ›´å¯é åœ°ä¸‹è½½ Google Drive æ–‡ä»¶")
            print("      è¿è¡Œ: pip install gdown")
            print("æ­£åœ¨ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ä¸‹è½½...")

        # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä½¿ç”¨ requests
        session = requests.Session()

        # ç¬¬ä¸€æ¬¡è¯·æ±‚
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        response = session.get(url, stream=True, timeout=30)

        # æ£€æŸ¥æ˜¯å¦æœ‰ç—…æ¯’æ‰«æè­¦å‘Š
        token = None
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                token = value
                break

        # å¦‚æœæœ‰è­¦å‘Šï¼Œè·å–ç¡®è®¤ token
        if token:
            params = {'id': file_id, 'confirm': token, 'export': 'download'}
            url = "https://drive.google.com/uc"
            response = session.get(url, params=params, stream=True, timeout=60)

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰çœŸå®æ–‡ä»¶ï¼Œå°è¯•ä»å“åº”ä¸­æå–ç¡®è®¤é“¾æ¥
        if response.headers.get('content-type', '').startswith('text/html'):
            # ä» HTML ä¸­æå–ä¸‹è½½é“¾æ¥
            import re
            content = response.content.decode('utf-8')
            match = re.search(r'href="/uc\?export=download&amp;confirm=([^&]+)&amp;id=' + file_id, content)
            if match:
                confirm = match.group(1)
                params = {'id': file_id, 'confirm': confirm, 'export': 'download'}
                url = "https://drive.google.com/uc"
                response = session.get(url, params=params, stream=True, timeout=60)

        response.raise_for_status()

        # è·å–æ–‡ä»¶å¤§å°
        total_size = int(response.headers.get('content-length', 0))

        if total_size == 0:
            print("âš ï¸  è­¦å‘Š: æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œå¯èƒ½ä¸‹è½½å¤±è´¥")
            print("å»ºè®®:")
            print("  1. å®‰è£… gdown: pip install gdown")
            print("  2. æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ° models/ ç›®å½•")
            return False

        # ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
        downloaded = 0
        with open(dest_path, 'wb') as f, tqdm(
            desc=os.path.basename(dest_path),
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as progress_bar:
            for chunk in response.iter_content(chunk_size=32768):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    progress_bar.update(len(chunk))

        # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶å¤§å°
        actual_size = os.path.getsize(dest_path)
        if actual_size < 1024 * 1024:  # å°äº 1MB
            print(f"âš ï¸  è­¦å‘Š: ä¸‹è½½çš„æ–‡ä»¶å¤ªå° ({actual_size} bytes)ï¼Œå¯èƒ½ä¸‹è½½å¤±è´¥")
            print("å»ºè®®:")
            print("  1. å®‰è£… gdown: pip install gdown")
            print("  2. æˆ–æ‰‹åŠ¨ä¸‹è½½: " + f"https://drive.google.com/file/d/{file_id}/view")
            os.remove(dest_path)
            return False

        return True

    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½å¤±è´¥: {e}")
        if os.path.exists(dest_path):
            os.remove(dest_path)
        return False
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        if os.path.exists(dest_path):
            os.remove(dest_path)
        return False


def download_file(url, dest_path, expected_md5=None):
    """
    ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦æ¡

    Args:
        url: ä¸‹è½½é“¾æ¥
        dest_path: ç›®æ ‡ä¿å­˜è·¯å¾„
        expected_md5: æœŸæœ›çš„ MD5 å€¼ï¼Œç”¨äºæ ¡éªŒ

    Returns:
        bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ Google Drive é“¾æ¥
        if 'drive.google.com' in url:
            # æå–æ–‡ä»¶ ID
            if 'id=' in url:
                file_id = url.split('id=')[1].split('&')[0]
            else:
                print("é”™è¯¯: æ— æ³•è§£æ Google Drive æ–‡ä»¶ ID")
                return False

            success = download_file_from_google_drive(file_id, dest_path)
        else:
            # æ™®é€š HTTP ä¸‹è½½
            print(f"æ­£åœ¨ä» {url} ä¸‹è½½...")

            # å‘é€ HEAD è¯·æ±‚è·å–æ–‡ä»¶å¤§å°
            response = requests.head(url, allow_redirects=True, timeout=10)
            total_size = int(response.headers.get('content-length', 0))

            # å¼€å§‹ä¸‹è½½
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()

            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(os.path.dirname(dest_path), exist_ok=True)

            # ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
            with open(dest_path, 'wb') as f, tqdm(
                desc=os.path.basename(dest_path),
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as progress_bar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        progress_bar.update(len(chunk))

            success = True

        # éªŒè¯ MD5
        if success and expected_md5:
            print("æ­£åœ¨éªŒè¯æ–‡ä»¶å®Œæ•´æ€§...")
            actual_md5 = calculate_md5(dest_path)
            if actual_md5.lower() != expected_md5.lower():
                print(f"é”™è¯¯: MD5 æ ¡éªŒå¤±è´¥!")
                print(f"  æœŸæœ›å€¼: {expected_md5}")
                print(f"  å®é™…å€¼: {actual_md5}")
                os.remove(dest_path)
                return False
            print("æ–‡ä»¶æ ¡éªŒé€šè¿‡ âœ“")

        return success

    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½å¤±è´¥: {e}")
        if os.path.exists(dest_path):
            os.remove(dest_path)
        return False
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        if os.path.exists(dest_path):
            os.remove(dest_path)
        return False


def download_model(model_key):
    """
    ä¸‹è½½æŒ‡å®šçš„æ¨¡å‹

    Args:
        model_key: æ¨¡å‹é…ç½®çš„é”®å

    Returns:
        bool: æ˜¯å¦æˆåŠŸä¸‹è½½
    """
    if model_key not in MODEL_CONFIGS:
        print(f"é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹é…ç½® '{model_key}'")
        print(f"å¯ç”¨çš„æ¨¡å‹: {', '.join(MODEL_CONFIGS.keys())}")
        return False

    config = MODEL_CONFIGS[model_key]
    dest_path = os.path.join(MODELS_DIR, config['filename'])

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(dest_path):
        print(f"æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨: {dest_path}")

        # å¦‚æœæœ‰ MD5ï¼ŒéªŒè¯ç°æœ‰æ–‡ä»¶
        if config['md5']:
            print("æ­£åœ¨éªŒè¯ç°æœ‰æ–‡ä»¶...")
            actual_md5 = calculate_md5(dest_path)
            if actual_md5.lower() == config['md5'].lower():
                print("ç°æœ‰æ–‡ä»¶æ ¡éªŒé€šè¿‡ âœ“")
                return True
            else:
                print("ç°æœ‰æ–‡ä»¶å·²æŸåï¼Œå°†é‡æ–°ä¸‹è½½...")
                os.remove(dest_path)
        else:
            response = input("æ˜¯å¦é‡æ–°ä¸‹è½½? (y/N): ")
            if response.lower() != 'y':
                return True

    # ä¸‹è½½æ¨¡å‹
    print(f"\næ­£åœ¨ä¸‹è½½ {config['name']}...")
    success = download_file(config['url'], dest_path, config['md5'])

    if success:
        print(f"âœ“ æ¨¡å‹å·²æˆåŠŸä¸‹è½½åˆ°: {dest_path}")
        file_size = os.path.getsize(dest_path) / (1024 * 1024)  # MB
        print(f"  æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        return True
    else:
        print(f"âœ— æ¨¡å‹ä¸‹è½½å¤±è´¥")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ–‡æ¡£å¢å¼ºæ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print()

    # åˆ›å»ºæ¨¡å‹ç›®å½•
    os.makedirs(MODELS_DIR, exist_ok=True)
    print(f"æ¨¡å‹å­˜å‚¨ç›®å½•: {MODELS_DIR}")
    print()

    # æ˜¾ç¤ºæç¤ºä¿¡æ¯
    print("âœ¨ DocEnTR æ¨¡å‹ä¸‹è½½å·¥å…·")
    print()
    print("ğŸ“š æ¨¡å‹æ¥æº: https://github.com/dali92002/DocEnTR")
    print("   è®ºæ–‡: DocEnTr: An End-to-End Document Image Enhancement Transformer")
    print("   ä¼šè®®: ICPR 2022")
    print()
    print("ğŸ“Œ å¯ç”¨æ¨¡å‹:")
    print("   æœ¬å·¥å…·æä¾› 6 ä¸ªé¢„è®­ç»ƒçš„ DocEnTR æ¨¡å‹ï¼Œåˆ†åˆ«åœ¨ä¸åŒçš„")
    print("   DIBCO æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œé€‚ç”¨äºæ–‡æ¡£å›¾åƒå¢å¼ºï¼ˆäºŒå€¼åŒ–ï¼‰ä»»åŠ¡ã€‚")
    print()
    print("   - Base æ¨¡å‹: ä½¿ç”¨ 8x8 patch size")
    print("   - Large æ¨¡å‹: ä½¿ç”¨ 16x16 patch size")
    print()
    print("âš ï¸  æ³¨æ„äº‹é¡¹:")
    print("   1. è¿™äº›æ¨¡å‹æ˜¯åŸºäº Transformer æ¶æ„ï¼Œä¸æœ¬é¡¹ç›®çš„ U-Net ä¸å…¼å®¹")
    print("   2. è¦ä½¿ç”¨è¿™äº›æ¨¡å‹ï¼Œéœ€è¦å…‹éš† DocEnTR çš„ä»£ç :")
    print("      git clone https://github.com/dali92002/DocEnTR")
    print("   3. ä¸‹è½½çš„æƒé‡æ–‡ä»¶åº”é…åˆ DocEnTR çš„ä»£ç ä½¿ç”¨")
    print()
    print("ğŸ’¡ æ¨èé€‰æ‹©:")
    print("   å¯¹äºä¸€èˆ¬æ–‡æ¡£å¢å¼ºä»»åŠ¡ï¼Œæ¨èä¸‹è½½ H-DIBCO 2012 çš„æ¨¡å‹ï¼Œ")
    print("   å› ä¸ºå®ƒçš„ PSNR æœ€é«˜ï¼ˆ22.29 for Base, 22.04 for Largeï¼‰")
    print()

    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
    print("å¯ä¸‹è½½çš„æ¨¡å‹:")
    for i, (key, config) in enumerate(MODEL_CONFIGS.items(), 1):
        status = "âœ“" if os.path.exists(os.path.join(MODELS_DIR, config['filename'])) else "âœ—"
        psnr_info = f"PSNR: {config['psnr']}" if 'psnr' in config else ""
        print(f"  {i}. [{status}] {config['name']}")
        if psnr_info:
            print(f"      {psnr_info}")
    print()

    # è¯¢é—®ç”¨æˆ·è¦ä¸‹è½½å“ªä¸ªæ¨¡å‹
    choice = input("è¯·é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹ç¼–å· (1-{}, æˆ–æŒ‰ Enter ä¸‹è½½æ‰€æœ‰): ".format(len(MODEL_CONFIGS)))

    if choice.strip() == '':
        # ä¸‹è½½æ‰€æœ‰æ¨¡å‹
        print("\nå¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
        success_count = 0
        for key in MODEL_CONFIGS.keys():
            if download_model(key):
                success_count += 1
            print()

        print(f"å®Œæˆ! æˆåŠŸä¸‹è½½ {success_count}/{len(MODEL_CONFIGS)} ä¸ªæ¨¡å‹")
    else:
        # ä¸‹è½½æŒ‡å®šæ¨¡å‹
        try:
            index = int(choice) - 1
            model_keys = list(MODEL_CONFIGS.keys())
            if 0 <= index < len(model_keys):
                download_model(model_keys[index])
            else:
                print("é”™è¯¯: æ— æ•ˆçš„é€‰æ‹©")
                sys.exit(1)
        except ValueError:
            print("é”™è¯¯: è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            sys.exit(1)


if __name__ == '__main__':
    main()

